{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "from tqdm import tqdm\n",
    "import struct\n",
    "import pickle\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "import scipy as sp\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "np.seterr('raise')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def read_complex_binary2(filename):\n",
    "    \"\"\" Read file of float32 into complex array.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        bytes = f.read()\n",
    "    data = np.frombuffer(bytes, dtype=np.float32).reshape(-1, 2)\n",
    "    data = data[:, 0] + 1j*data[:, 1]\n",
    "    return data\n",
    "\n",
    "def get_rssis(filename):\n",
    "    \"\"\" Get RSSI time series from file.\n",
    "    \"\"\"\n",
    "    rssis = []\n",
    "    data = read_complex_binary2(filename)\n",
    "    num_frame = int(len(data)/65536 - 2)\n",
    "    for i in range(num_frame):\n",
    "        section = data[i*65536:(i+1)*65536]\n",
    "        spectrum = 10*np.log10(np.fft.fftshift(np.abs(np.fft.fft(section))**2))\n",
    "        rssis.append(np.max(spectrum[22929:22949]))\n",
    "    rssis = np.array(rssis)\n",
    "    return rssis\n",
    "\n",
    "def get_test_grid(dirname, prefix, xs=None, ys=None):\n",
    "    \"\"\" Get test grid from xs, ys.\n",
    "    \"\"\"\n",
    "    test_rssis = {}\n",
    "    \n",
    "    if xs is None or ys is None:\n",
    "        for filename in tqdm(glob.glob(os.path.join(dirname, f\"{prefix}*.dat\"))):\n",
    "            coords = os.path.splitext(os.path.basename(filename))[0][1:]\n",
    "            x, y = int(coords[:2]), int (coords[2:])\n",
    "            \n",
    "            filename_cached = os.path.splitext(filename)[0] + '.pkl'\n",
    "            if os.path.exists(filename_cached):\n",
    "                with open(filename_cached, 'rb') as f:\n",
    "                    mean, std = pickle.load(f)\n",
    "                test_rssis[x,y] = mean\n",
    "            else:\n",
    "                rssis = get_rssis(filename)\n",
    "                if len(rssis):\n",
    "                    mean, std = np.mean(rssis), np.std(rssis)\n",
    "                    with open(filename_cached, 'wb') as f:\n",
    "                        pickle.dump((mean,std), f)\n",
    "                    test_rssis[x,y] = mean\n",
    "                \n",
    "    else:\n",
    "        for i, x in enumerate(tqdm(xs)):\n",
    "            for j, y in enumerate(ys):\n",
    "                filename = os.path.join(dirname, f\"{prefix}{x:>02}{y:>02}.dat\")\n",
    "                filename_cached = os.path.splitext(filename)[0] + '.pkl'\n",
    "                if os.path.exists(filename_cached):\n",
    "                    with open(filename_cached, 'rb') as f:\n",
    "                        mean, std = pickle.load(f)\n",
    "                    test_rssis[x,y] = mean\n",
    "                else:\n",
    "                    rssis = get_rssis(filename)\n",
    "                    if len(rssis):\n",
    "                        mean, std = np.mean(rssis), np.std(rssis)\n",
    "                        with open(filename_cached, 'wb') as f:\n",
    "                            pickle.dump((mean,std), f)\n",
    "                        test_rssis[x,y] = mean\n",
    "    \n",
    "    return test_rssis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_linear(dirname, prefix, xs, ys):\n",
    "    \"\"\" Get the linear model from directory of data files.\n",
    "    \"\"\"\n",
    "    s_mean = np.full_like(np.meshgrid(xs,ys)[0], np.nan, dtype=np.float64)\n",
    "\n",
    "    for i, x in enumerate(tqdm(xs)):\n",
    "        for j, y in enumerate(ys):\n",
    "            filename = os.path.join(dirname, f\"{prefix}{x:>02}{y:>02}.dat\")\n",
    "            filename_cached = os.path.splitext(filename)[0] + '.pkl'\n",
    "            if os.path.exists(filename_cached):\n",
    "                with open(filename_cached, 'rb') as f:\n",
    "                    mean, std = pickle.load(f)\n",
    "                s_mean[i,j] = mean\n",
    "            else:\n",
    "                rssis = get_rssis(filename)\n",
    "                if len(rssis):\n",
    "                    mean, std = np.mean(rssis), np.std(rssis)\n",
    "                    with open(filename_cached, 'wb') as f:\n",
    "                        pickle.dump((mean,std), f)\n",
    "                    s_mean[i,j] = mean\n",
    "    \n",
    "    X, Y = np.meshgrid(xs,ys)\n",
    "    A = np.sqrt(X**2+Y**2).flatten().reshape(-1, 1)\n",
    "    b = s_mean.flatten().reshape(-1, 1)\n",
    "    rssi2dist = LinearRegression().fit(b, A)\n",
    "\n",
    "    return rssi2dist\n",
    "\n",
    "def localize_linear(rssis, rssi2dist, n):\n",
    "    \"\"\" Compute location estimate using maximum-likelihood estimation.\n",
    "    \"\"\"\n",
    "    d1, d2, d3, d4 = [rssi2dist.predict(np.array(rssi).reshape(1, -1)) for rssi in rssis]\n",
    "    \n",
    "    xs = np.arange(0, n+0.1, 0.1)\n",
    "    ys = np.arange(0, n+0.1, 0.1)\n",
    "    \n",
    "    error_grid = np.zeros_like(np.meshgrid(xs,ys)[0], dtype=np.float64)\n",
    "    for i, x in enumerate(xs):\n",
    "        for j, y in enumerate(ys):\n",
    "            d1_ = np.sqrt(x**2+y**2)\n",
    "            d2_ = np.sqrt((n-y)**2 + x**2)\n",
    "            d3_ = np.sqrt((n-x)**2 + (n-y)**2)\n",
    "            d4_ = np.sqrt(y**2 + (n-x)**2)\n",
    "            error_grid[i,j] = (d1-d1_)**2 + (d2-d2_)**2 + (d3-d3_)**2 + (d4-d4_)**2\n",
    "    \n",
    "    result = np.unravel_index(np.argmin(error_grid), error_grid.shape)\n",
    "    \n",
    "    return result[0]/10.0, result[1]/10.0\n",
    "\n",
    "def run_lr(dirname, n,\n",
    "           train_prefix, test_prefix, \n",
    "           train_xs, train_ys, test_xs, test_ys):\n",
    "    \n",
    "    test_grid = get_test_grid(dirname, test_prefix, test_xs, test_ys)\n",
    "    rssi2dist = get_model_linear(dirname, train_prefix, train_xs, train_ys)\n",
    "\n",
    "    # Start testing\n",
    "    errors = []\n",
    "    prediction_record=[]\n",
    "    for (x,y) in tqdm(test_grid.keys()):\n",
    "        rssis = [test_grid[x, y], \n",
    "                 test_grid[n-y, x],\n",
    "                 test_grid[n-x, n-y], \n",
    "                 test_grid[y, n-x]]\n",
    "        x_pred, y_pred = localize_linear(rssis, rssi2dist, n)\n",
    "        errors.append(np.sqrt((x-x_pred)**2+(y-y_pred)**2))\n",
    "        prediction_record.append([x,y,x_pred,y_pred])\n",
    "    print(f\"mean error: {np.mean(errors)}\")\n",
    "    print(f\"median error: {np.median(errors)}\")\n",
    "    print(f\"stdev error: {np.std(errors)}\")\n",
    "    \n",
    "    return errors, prediction_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [00:00<00:00, 46752.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 10450.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:04<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error: 2.8624626117782066\n",
      "median error: 3.047950130825634\n",
      "stdev error: 0.8430612318309594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 118/118 [00:00<00:00, 44296.78it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 5222.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:08<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error: 3.4654428132067077\n",
      "median error: 3.5128336140500593\n",
      "stdev error: 1.2452735074649208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 35649.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 8533.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error: 3.4020600310680744\n",
      "median error: 3.6674241641784495\n",
      "stdev error: 1.29197041181642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "errors_lr = []\n",
    "\n",
    "# Dataset\n",
    "# dirname = 'data/Sep 17- redo water'\n",
    "# n = 10 # grid is 0 to n (n+1 by n+1)\n",
    "# # AEM*\n",
    "# train_prefix = 0\n",
    "# train_xs = np.arange(0,n+1,2)\n",
    "# train_ys = np.arange(0,n+1,2)\n",
    "# test_prefix = 1\n",
    "# # Run prediction\n",
    "# errors, prediction_record = run_lr(dirname, n,\n",
    "#                                    train_prefix, test_prefix,\n",
    "#                                    train_xs, train_ys, None, None)\n",
    "# errors_lr += errors\n",
    "\n",
    "# Dataset\n",
    "dirname = 'data/sep-18-first'\n",
    "n = 10 # grid is 0 to n (n+1 by n+1)\n",
    "# AEM*\n",
    "train_prefix = 0\n",
    "train_xs = np.arange(0,n+1,2)\n",
    "train_ys = np.arange(0,n+1,2)\n",
    "test_prefix = 1\n",
    "# Run prediction\n",
    "errors, prediction_record = run_lr(dirname, n,\n",
    "                                   train_prefix, test_prefix,\n",
    "                                   train_xs, train_ys, None, None)\n",
    "errors_lr += errors\n",
    "\n",
    "# Dataset\n",
    "dirname = 'data/sep-19-full'\n",
    "n = 10 # grid is 0 to n (n+1 by n+1)\n",
    "# AEM*\n",
    "train_prefix = 0\n",
    "train_xs = np.arange(0,n+1,2)\n",
    "train_ys = np.arange(0,n+1,2)\n",
    "test_prefix = 1\n",
    "# Run prediction\n",
    "errors, prediction_record = run_lr(dirname, n,\n",
    "                                   train_prefix, test_prefix,\n",
    "                                   train_xs, train_ys, None, None)\n",
    "\n",
    "errors_lr += errors\n",
    "\n",
    "# Dataset\n",
    "dirname = 'data/sep-20-redo'\n",
    "n = 10 # grid is 0 to n (n+1 by n+1)\n",
    "# AEM*\n",
    "train_prefix = 0\n",
    "train_xs = np.arange(0,n+1,2)\n",
    "train_ys = np.arange(0,n+1,2)\n",
    "test_prefix = 1\n",
    "# Run prediction\n",
    "errors, prediction_record = run_lr(dirname, n,\n",
    "                                   train_prefix, test_prefix,\n",
    "                                   train_xs, train_ys, None, None)\n",
    "errors_lr += errors\n",
    "\n",
    "with open('errors_lr.pkl', 'wb') as f:\n",
    "    pickle.dump(errors_lr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
